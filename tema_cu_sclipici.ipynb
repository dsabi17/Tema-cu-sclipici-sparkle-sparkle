{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sktime\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_from_arff_to_dataframe\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating datasets and spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"datasets.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sports, y_train_sports = load_from_arff_to_dataframe('RacketSports\\RacketSports_TRAIN.arff')\n",
    "X_test_sports, y_test_sports = load_from_arff_to_dataframe('RacketSports\\RacketSports_TEST.arff')\n",
    "\n",
    "data_mitbih_train = pd.read_csv('ECG\\mitbih_train.csv', header=None)\n",
    "data_mitbih_test = pd.read_csv('ECG\\mitbih_test.csv', header=None)\n",
    "\n",
    "X_train_mitbih = data_mitbih_train.iloc[:, 0:-1]\n",
    "y_train_mitbih = data_mitbih_train.iloc[:, -1]\n",
    "\n",
    "X_test_mitbih = data_mitbih_test.iloc[:, 0:-1]\n",
    "y_test_mitbih = data_mitbih_test.iloc[:, -1]\n",
    "\n",
    "data_ptbdb_abnormal = pd.read_csv('ECG\\ptbdb_abnormal.csv', header=None)\n",
    "data_ptbdb_normal = pd.read_csv('ECG\\ptbdb_normal.csv', header=None)\n",
    "\n",
    "data_ptbdb = pd.concat([data_ptbdb_abnormal, data_ptbdb_normal])\n",
    "\n",
    "X_ptbdb = data_ptbdb.iloc[:, 0:-1]\n",
    "y_ptbdb = data_ptbdb.iloc[:, -1]\n",
    "\n",
    "X_train_ptbdb, X_test_ptbdb, y_train_ptbdb, y_test_ptbdb = train_test_split(X_ptbdb, y_ptbdb, test_size=0.2, random_state=80085)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sports = ['Badminton_Smash',\n",
    "                'Badminton_Clear',\n",
    "                'Squash_ForehandBoast',\n",
    "                'Squash_BackhandBoast']\n",
    "\n",
    "labels_mitbih = list(range(5))\n",
    "\n",
    "labels_ptbdb = [0, 1]\n",
    "\n",
    "datasets = [y_train_sports, y_test_sports, y_train_mitbih, y_test_mitbih, y_train_ptbdb, y_test_ptbdb]\n",
    "\n",
    "plot_labels = [labels_sports, labels_mitbih, labels_ptbdb]\n",
    "plot_titles = ['RacketSports', 'ECG Heartbeat Categorization Dataset - MIT-BIH', 'ECG Heartbeat Categorization Dataset - PTB Diagnostic']\n",
    "plot_subtitles = ['Train Set', 'Test Set']\n",
    "\n",
    "sns.set(rc={'figure.autolayout': True})\n",
    "\n",
    "bg_color = '#E5E6F0'\n",
    "color_line = '#0F101A'\n",
    "colors = ['#5465FF', '#788BFF', '#9BB1FF', '#BFD7FF', '#D1EAFF', '#E2FDFF']\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(colors))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.1**\n",
    "\n",
    "Grafice ale frecven»õei de apari»õie a fiecƒÉrei etichete (clase) √Æn setul de date de antrenare / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '3.1/1/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "for index in range(len(datasets)):\n",
    "    # bar plot for class imbalance and cute pie on the site\n",
    "    # print(datasets[index].shape)\n",
    "    # print(plot_titles[index // 2])\n",
    "    # print(plot_subtitles[index % 2])\n",
    "    # plt.figure(facecolor=bg_color)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7), facecolor=bg_color)\n",
    "    fig.suptitle(plot_subtitles[index % 2] + ' - ' + plot_titles[index // 2], fontsize=20)\n",
    "\n",
    "    sns.countplot(ax=axes[0], x=datasets[index], order=np.unique(plot_labels[index // 2]), edgecolor=color_line)\n",
    "    axes[0].set_facecolor(bg_color)\n",
    "\n",
    "    for p in axes[0].patches:\n",
    "        axes[0].bar_label(container=axes[0].containers[0])\n",
    "\n",
    "    counts = [len(datasets[index][datasets[index] == label]) for label in plot_labels[index//2]]\n",
    "    axes[1].pie(counts, labels=plot_labels[index // 2], autopct='%1.1f%%')\n",
    "\n",
    "    plt.savefig(results_dir + plot_titles[index // 2] + '_' + plot_subtitles[index % 2] + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.2**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) C√¢te un exemplu de serie pentru fiecare tip de ac»õiune din RacketSports - val de acc accelerometru si de giroscop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(80085)\n",
    "results_dir = '3.1/2/1/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "for label in labels_sports:\n",
    "    indexes = random.sample([i for i in range(y_train_sports.shape[0]) if y_train_sports[i] == label], 6)\n",
    "\n",
    "    # 3D acc\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Accelerometru - 3D', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_acc = X_train_sports.to_numpy()[indexes[i]][0].to_numpy()\n",
    "        y_acc = X_train_sports.to_numpy()[indexes[i]][1].to_numpy()\n",
    "        z_acc = X_train_sports.to_numpy()[indexes[i]][2].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, projection='3d', facecolor=bg_color)\n",
    "        ax.plot(x_acc, y_acc, z_acc, color=colors[0], zorder=-1)\n",
    "        ax.plot(x_acc, y_acc, z_acc, color=colors[4], marker='*', markeredgecolor=colors[0], markeredgewidth=1, markersize=10, linestyle=' ')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Accelerometru_3d' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    # axis acc\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Accelerometru - axe', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_acc = X_train_sports.to_numpy()[indexes[i]][0].to_numpy()\n",
    "        y_acc = X_train_sports.to_numpy()[indexes[i]][1].to_numpy()\n",
    "        z_acc = X_train_sports.to_numpy()[indexes[i]][2].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(x_acc, color=colors[0])\n",
    "        ax.plot(y_acc, color=colors[2])\n",
    "        ax.plot(z_acc, color=colors[3])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Accelerometru_axis' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Giroscop - 3D', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_giro = X_train_sports.to_numpy()[indexes[i]][3].to_numpy()\n",
    "        y_giro = X_train_sports.to_numpy()[indexes[i]][4].to_numpy()\n",
    "        z_giro = X_train_sports.to_numpy()[indexes[i]][5].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, projection='3d', facecolor=bg_color)\n",
    "        ax.plot(x_giro, y_giro, z_giro, color=colors[0], zorder=-1)\n",
    "        ax.plot(x_giro, y_giro, z_giro, color=colors[4], marker='*', markeredgecolor=colors[0], markeredgewidth=1, markersize=10, linestyle=' ')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Giroscop_3d' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Giroscop - axe', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_giro = X_train_sports.to_numpy()[indexes[i]][0].to_numpy()\n",
    "        y_giro = X_train_sports.to_numpy()[indexes[i]][1].to_numpy()\n",
    "        z_acc = X_train_sports.to_numpy()[indexes[i]][2].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(x_giro, color=colors[0])\n",
    "        ax.plot(y_giro, color=colors[2])\n",
    "        ax.plot(z_giro, color=colors[3])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Giroscop_axis' + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Afi»ôa»õi c√¢te un exemplu de serie pentru fiecare categorie de aritmie din seturile de date MIT-BIH / PTB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(80085)\n",
    "results_dir = '3.1/2/2/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 'ECG Heartbeat Categorization Dataset - MIT-BIH', 'ECG Heartbeat Categorization Dataset - PTB Diagnostic'\n",
    "time_sample = list(range(187))\n",
    "\n",
    "for label in labels_mitbih:\n",
    "    indexes = random.sample([i for i in range(y_train_mitbih.shape[0]) if y_train_mitbih[i] == label], 6)\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - MIT-BIH ' + str(label) , fontsize=20)\n",
    "    for i in range(6):\n",
    "        series = X_train_mitbih.to_numpy()[indexes[i]]\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(time_sample, series, color=colors[0], zorder=-1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_MIT_BIH_' + str(label) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "for label in labels_ptbdb:\n",
    "    indexes = random.sample([i for i in range(y_train_ptbdb.shape[0]) if y_train_ptbdb.to_numpy()[i] == label], 6)\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - PTB Diagnostic ' + str(label) , fontsize=20)\n",
    "    for i in range(6):\n",
    "        series = X_train_ptbdb.to_numpy()[indexes[i]]\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(time_sample, series, color=colors[0], zorder=-1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_PTB_Diagnostic_' + str(label) + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Pentru seturile de date cu aritmii afi»ôa»õi un grafic al mediei »ôi devia»õiei standard\n",
    "per unitate de timp, pentru fiecare clasƒÉ de aritmie. Media »ôi devia»õia standard se\n",
    "calculeazƒÉ peste toate exemplele (at√¢t din train, c√¢t »ôi din train set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '3.1/2/3/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "X_mitbih = pd.concat([X_train_mitbih, X_test_mitbih]).to_numpy()\n",
    "y_mitbih = pd.concat([y_train_mitbih, y_test_mitbih]).to_numpy()\n",
    "\n",
    "\n",
    "for label in labels_mitbih:\n",
    "    indexes = [i for i in range(y_mitbih.shape[0]) if y_mitbih[i] == label]\n",
    "\n",
    "    std_mitbih = np.std(X_mitbih[indexes], axis=0)\n",
    "    mean_mitbih = np.mean(X_mitbih[indexes], axis=0)\n",
    "\n",
    "    fig = plt.figure(facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - MIT-BIH ' + str(label) , fontsize=20)\n",
    "    ax = fig.add_subplot(1, 1, 1, facecolor=bg_color)\n",
    "    ax.set_title('Standard Deviation and Mean')\n",
    "    ax.plot(time_sample, std_mitbih, color=colors[3], linewidth=2.5)\n",
    "    ax.plot(time_sample, mean_mitbih, color=colors[2], linewidth=2, zorder=-1)\n",
    "\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_MIT_BIH_mean_std_' + str(label) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for label in labels_ptbdb:\n",
    "    indexes = [i for i in range(y_ptbdb.shape[0]) if y_ptbdb.to_numpy()[i] == label]\n",
    "    std_ptbdb = np.std(X_ptbdb.to_numpy()[indexes], axis=0)\n",
    "    mean_ptbdb = np.mean(X_ptbdb.to_numpy()[indexes], axis=0)\n",
    "\n",
    "    fig = plt.figure(facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - PTB Diagnostic ' + str(label) , fontsize=20)\n",
    "    ax = fig.add_subplot(1, 1, 1, facecolor=bg_color)\n",
    "    ax.set_title('Standard Deviation and Mean')\n",
    "    ax.plot(time_sample, std_ptbdb, color=colors[3], linewidth=2.5)\n",
    "    ax.plot(time_sample, mean_ptbdb, color=colors[2], linewidth=2, zorder=-1)\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_PTB_Diagnostic_mean_std_' + str(label) + '.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Pentru setul de date RacketSports afi»ôa»õi distribu»õia valorilor per fiecare axƒÉ de\n",
    "accelerometru »ôi giroscop √Æn parte / per ac»õiune (a se vedea un exemplu fictiv de\n",
    "output √Æn Figura 1). O astfel de analizƒÉ este utilƒÉ pentru a determina dacƒÉ existƒÉ ni»ôte\n",
    "»ôabloane imediate care se pot observa √Æn termen de valori specifice pe x, y »ôi z\n",
    "pentru fiecare gest √Æn parte. Aceste »ôabloane (e.g. intervale de valori specifice) pot fi\n",
    "folosite √Æn etapa de definire a atributelor »ôi pot totodatƒÉ informa dacƒÉ problema este\n",
    "una u»ôoarƒÉ (»ôabloane de valori clar diferen»õiabile per gest) sau grea (distribu»õii\n",
    "similare per fiecare gest).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why did i do it like this? why is my code so inefficient? why is it so bad?\n",
    "# because i do not care anymore\n",
    "# ive spent literal hours of my life on this amazing ü§¨ thing and i do not want to see it anymore\n",
    "# now it works and i dont care\n",
    "# let it rot for all i care\n",
    "\n",
    "results_dir = '3.1/2/4/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "colors = ['#cafe48', '#70f8ba', '#d14081', '#2583d0', '#733ab1', '#ff8811']\n",
    "\n",
    "data_sports_all = pd.concat([X_train_sports, X_test_sports], ignore_index=True)\n",
    "columns_sports = data_sports_all.columns\n",
    "y_sports_all = np.append(y_train_sports, y_test_sports)\n",
    "\n",
    "parsed_data = {}\n",
    "labels = []\n",
    "values = []\n",
    "dimensions = []\n",
    "\n",
    "for i in range(len(data_sports_all)):\n",
    "    for col in ['dim_0', 'dim_1', 'dim_2']:\n",
    "        time_series = data_sports_all[col][i]\n",
    "        for value in time_series:\n",
    "            values.append(value)\n",
    "            labels.append(y_sports_all[i])\n",
    "            dimensions.append(col)\n",
    "\n",
    "parsed_data['value'] = values\n",
    "parsed_data['dimension'] = dimensions\n",
    "parsed_data['label'] = labels\n",
    "\n",
    "parsed_data = pd.DataFrame(parsed_data)\n",
    "\n",
    "g = sns.FacetGrid(parsed_data, col='dimension', hue='label', aspect=1.5).map(sns.histplot, 'value', kde=True).add_legend()\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.savefig(results_dir + 'value_distr_1' + str(label) + '.png')\n",
    "\n",
    "parsed_data = {}\n",
    "labels = []\n",
    "values = []\n",
    "dimensions = []\n",
    "\n",
    "for i in range(len(data_sports_all)):\n",
    "    for col in ['dim_3', 'dim_4', 'dim_5']:\n",
    "        time_series = data_sports_all[col][i]\n",
    "        for value in time_series:\n",
    "            values.append(value)\n",
    "            labels.append(y_sports_all[i])\n",
    "            dimensions.append(col)\n",
    "\n",
    "parsed_data['value'] = values\n",
    "parsed_data['dimension'] = dimensions\n",
    "parsed_data['label'] = labels\n",
    "\n",
    "parsed_data = pd.DataFrame(parsed_data)\n",
    "\n",
    "g = sns.FacetGrid(parsed_data, col='dimension', hue='label', aspect=1.5).map(sns.histplot, 'value', kde=True)\n",
    "g.add_legend()\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.savefig(results_dir + 'value_distr_2' + str(label) + '.png')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # for label in labels_sports:\n",
    "# #     indexes = [i for i in range(y_train_sports.shape[0]) if y_train_sports[i] == label]\n",
    "# #     data_sports_parsed = pd.DataFrame()\n",
    "# #     working_data = X_train_sports.iloc[indexes]\n",
    "# #     # print(working_data.columns)\n",
    "# #     for col in columns_sports:\n",
    "# #         values = np.zeros((30 * len(working_data)))\n",
    "# #         for i in range(30 * len(working_data)):\n",
    "# #             values[i] = working_data['dim_0'].to_numpy()[i//30][i % 30]\n",
    "# #         data_sports_parsed[col] = values\n",
    "\n",
    "# #     for col in columns_sports:\n",
    "# #         sns.histplot(data=data_sports_parsed, x=col, color=)\n",
    "# #     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # print(values)\n",
    "# # sns.histplot(data=X_train_sports, kde=True)\n",
    "# # Unde <nume variabila target> reprezinta numele atributului din setul de date ce identificƒÉ\n",
    "# # eticheta gestului, <numar clase posibile> este 4 pentru setul de date RacketSport, iar <nume\n",
    "# # dimensiune x, y, sau z> este numele atributului pe care √Æl da»õi la √ÆncƒÉrcare setului de 300\n",
    "# # valori care corespund axei x, y sau z dupƒÉ caz.\n",
    "\n",
    "# # print(X_train_sports)\n",
    "# # print(y_train_sports.type)\n",
    "\n",
    "# data_sports_parsed = pd.DataFrame()\n",
    "# for col in columns_sports:\n",
    "#     values = np.zeros((30 * len(data_sports)))\n",
    "#     if col != 'label':\n",
    "#         for i in range(30 * len(data_sports)):\n",
    "#             values[i] = data_sports[col].to_numpy()[i//30][i % 30]\n",
    "#         data_sports_parsed[col] = values\n",
    "#     else:\n",
    "#         values = np.empty((30 * len(data_sports)), dtype='object')\n",
    "#         for i in range(30 * len(data_sports)):\n",
    "#             values[i] = data_sports[col].to_numpy()[i//30]\n",
    "#         print(values)\n",
    "\n",
    "# for col in columns_sports:\n",
    "#     if col != 'label':\n",
    "#         sns.histplot(data=data_sports_parsed, x=col)\n",
    "# plt.show()\n",
    "\n",
    "# # sns.displot(data_sports_parsed, x='dim_0', hue='label', binwidth=3, height=3, facet_kws=dict(margin_titles=True))\n",
    "# # g = sns.FacetGrid(data_sports_parsed, col='label', height=3.5, aspect=.65)\n",
    "# # g.map(sns.histplot, \"dim_0\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# print(type(X_train_sports['dim_0'][0]))\n",
    "\n",
    "# sns.FacetGrid(data_sports, hue = 'label').map(sns.displot, 'dim_0').add_legend()\n",
    "\n",
    "convert_dict = {'dim_0': np.ndarray}\n",
    "\n",
    "# print(type(data_sports.to_numpy()))\n",
    "# for col in ['dim_0']:\n",
    "#     print(data_sports[col].to_numpy()[0].to_numpy())\n",
    "\n",
    "\n",
    "\n",
    "# sns.displot(data=data_sports, x='dim_0', kde=True)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru analiza celor douƒÉ seturi de date ve»õi folosi urmƒÉtorii algoritmi:\n",
    "\n",
    "\n",
    "‚óè RandomForest - folosi»õi implementarea din scikit-learn [0.5p]\n",
    "‚óè GradientBoosted Trees - folosi»õi implementarea din biblioteca xgboost [0.75p]\n",
    "‚óè SVM - folosi»õi implementarea din scikit-learn [0.75p]\n",
    "\n",
    "\n",
    "\n",
    "Folosi»õi √Æn»õelegerea datelor c√¢»ôtigatƒÉ la pasul 3.1 pentru a determina dacƒÉ este necesarƒÉ\n",
    "standardizarea datelor. Acest pas este unul des √Ænt√¢lnit etapƒÉ de pre-procesare a datelor\n",
    "√Ænainte de antrenarea unui clasificator, √Æn vederea uniformizƒÉrii valorilor numerice aferente\n",
    "fiecƒÉrui tip de atribut (e.g. nu este dorit ca unele atribute sa aibƒÉ valori de ordinul miilor, iar\n",
    "altele de ordinul unitƒÉ»õilor).\n",
    "\n",
    "\n",
    "\n",
    "Partea de extragere a atributelor propusƒÉ √Æn sec»õiunea 3.2.2 poate duce la un numƒÉr mare\n",
    "de atribute extrase. Frecvent se √Ænt√¢mplƒÉ ca nu toate atributele sƒÉ aibƒÉ o contribu»õie\n",
    "importantƒÉ √Æn cadrul predic»õiei.\n",
    "Ca atare, investiga»õi aplicarea tehnicilor de selectare a atributelor (eng. Feature selection)\n",
    "oferite √Æn scikit-learn. Folosi»õi cel pu»õin una din metodele Variance Threshold sau Select\n",
    "Percentile.\n",
    "\n",
    "\n",
    "Fiecare algoritm din cei propu»ôi are o serie de hiper-parametrii care influen»õeazƒÉ\n",
    "func»õionarea acestuia. Pentru a gƒÉsi valorile potrivite pentru ace»ôtia ve»õi folosi o procedurƒÉ\n",
    "de cƒÉutare a hiper-parametrilor pe bazƒÉ de Grid Search cu Cross Validation.\n",
    "Setul minim de hiper-parametrii de cƒÉutat este:\n",
    "\n",
    "\n",
    "‚óè SVM: tipul de kernel, parametru C de regularizare\n",
    "‚óè RandomForest: numƒÉrul de arbori, ad√¢ncimea maximƒÉ a unui arbore, procentul din\n",
    "input folosit la antrenarea fiecƒÉrui arbore\n",
    "‚óè GradientBoostedTrees: numƒÉrul de arbori, ad√¢ncimea maximƒÉ a unui arbore,\n",
    "learning rate\n",
    "\n",
    "\n",
    "Evaluarea algoritmilor\n",
    "√én raportul vostru trebuie sa prezenta»õi urmƒÉtoarele:\n",
    "‚óè Rezultatul procedurii de feature selection: numƒÉrul total de feature-uri considerate »ôi\n",
    "numƒÉrul total de feature-uri utilizate la antrenare (ca urmare a procedurii de feature\n",
    "selection)\n",
    "‚óè Pentru fiecare algoritm, realiza»õi un tabel √Æn care sƒÉ prezenta»õi media si varian»õa\n",
    "pentru acurate»õea generalƒÉ de clasificare, precizie / recall / F1 la nivelul fiecƒÉrei\n",
    "clase √Æn parte\n",
    "‚óã Pe linii va fi indexatƒÉ configura»õia de hiper-parametrii rezultatƒÉ din procedura\n",
    "de GridSearch.\n",
    "‚óã Pe coloane vor fi prezentate metricile cerute\n",
    "‚óã Releva»õi prin bolduire valorile maxime pentru fiecare metricƒÉ\n",
    "‚óè Pentru cea mai bunƒÉ variantƒÉ a hiper-parametrilor, pentru fiecare algoritm,\n",
    "realiza»õi o matrice de confuzie peste clase."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2\n",
    "\n",
    "\n",
    "A. Extragere de atribute pentru RacketSports [1p]\n",
    "Datele din RacketSports reprezinta valori continue pe fiecare axƒÉ ale unor ac»õiuni cu 300 de\n",
    "observa»õii per serie. Ca atare, setul de atribute agregate pe care le putem extrage se referƒÉ\n",
    "la analiza statisticƒÉ a semnalelor pe fiecare axƒÉ.\n",
    "Sugestii de atribute statistice de extras per serie (sau sub-fereastrƒÉ a seriei) / per axƒÉ:\n",
    "\n",
    "\n",
    "‚óè medie\n",
    "\n",
    "‚óè abaterea standard\n",
    "\n",
    "‚óè abaterea medie absolutƒÉ\n",
    "\n",
    "‚óè valoare minimƒÉ\n",
    "\n",
    "‚óè valoare maximƒÉ\n",
    "\n",
    "‚óè diferenta de valori maxime si minime\n",
    "\n",
    "‚óè medianƒÉ\n",
    "\n",
    "‚óè abaterea medianƒÉ absolutƒÉ\n",
    "\n",
    "‚óè intervalul intercuartil\n",
    "\n",
    "‚óè NumƒÉr de valori negative\n",
    "\n",
    "‚óè NumƒÉr de valori pozitive\n",
    "\n",
    "‚óè numƒÉr de valori peste medie\n",
    "\n",
    "‚óè numƒÉr de v√¢rfuri\n",
    "\n",
    "‚óè Energia semnalului\n",
    "\n",
    "‚óã Energia unui semnal pe fiecare axƒÉ este calculatƒÉ lu√¢nd media sumei\n",
    "\n",
    "pƒÉtratelor valorilor dintr-o fereastrƒÉ pe axa respectivƒÉ.\n",
    "\n",
    "‚óè Asimetrie (skewness)\n",
    "\n",
    "‚óè CurtozƒÉ (kurtosis)\n",
    "\n",
    "‚óè Accelera»õia medie rezultantƒÉ\n",
    "\n",
    "‚óã Accelera»õia medie rezultantƒÉ peste fereastrƒÉ este calculatƒÉ lu√¢nd media\n",
    "rƒÉdƒÉcinilor pƒÉtrate ale valorilor din fiecare dintre cele trei axe pƒÉtrate »ôi\n",
    "adunate √ÆmpreunƒÉ.\n",
    "\n",
    "‚óè Aria mƒÉrimii semnalului\n",
    "\n",
    "‚óã Aria mƒÉrimii semnalului este definitƒÉ ca suma valorilor absolute ale celor\n",
    "trei axe mediate pe o fereastrƒÉ.\n",
    "\n",
    "\n",
    "\n",
    "√én afarƒÉ de atributele statistice, pentru secven»õe numerice interpretate ca semnale se pot\n",
    "calcula atribute extrase pe baza interpretƒÉrii √Æn regim de frecven»õƒÉ a semnalului (i.e.\n",
    "aplic√¢nd o transformatƒÉ Fourier).\n",
    "Pentru exemple »ôi cod de extragere a atributelor, at√¢t statistice c√¢t »ôi Fourier, urmƒÉri»õi acest\n",
    "tutorial.\n",
    "B. Extragere de atribute pentru Seturile de date cu Aritmii [1p]\n",
    "Pentru seturile MIT-BIH si PBT ve»õi √Æncerca sƒÉ antrena»õi algoritmii de la punctul 3.2.1\n",
    "folosind:\n",
    "‚óè Direct datele de intrare (fiecare din cele 187 de puncte ale unei serii\n",
    "reprezent√¢nd bƒÉtaia inimii este un atribut)\n",
    "‚óè Atributele statistice descrise la litera A.\n",
    "NOTƒÇ: extragerile de atribute prezentate mai sus pot fi aplicate pe toatƒÉ lungimea\n",
    "seriei sau pot fi aplicate pe ferestre de lungime H, unde H < lungimea secven»õei.\n",
    "Aceasta √ÆnseamnƒÉ cƒÉ pute»õi √ÆmpƒÉr»õi secven»õa voastrƒÉ √Æn subsecven»õe (cu sau fƒÉra\n",
    "suprapunere) »ôi sƒÉ calcula»õi atributele pe fiecare subsecven»õƒÉ √Æn parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_extractor:\n",
    "    def __init__(self, time_series, labels, W=20, sample_step=15):\n",
    "        self.time_series = time_series\n",
    "        self.labels = labels\n",
    "        self.W = W\n",
    "\n",
    "        # self.data = [(self.time_series[index][i:i + self.W], index)\n",
    "        #              for index in range(len(self.time_series))\n",
    "        #              for i in range(0, len(self.time_series[index]), sample_step)]\n",
    "\n",
    "        # self.indexes = [self.labels[i // len(self.time_series)] + '_' + str(i % len(self.time_series)) for i in range(len(self.data))]\n",
    "\n",
    "        self.data = []\n",
    "        self.indexed_labels = []\n",
    "\n",
    "        for i in range(len(time_series)):\n",
    "            count = 0\n",
    "            for step in range(0, len(self.time_series[i]), sample_step):\n",
    "                self.data.append(self.time_series[i][step : step + self.W])\n",
    "                self.indexed_labels.append(self.labels[i] + '_' + str(count))\n",
    "                count += 1\n",
    "        self.count = count\n",
    "\n",
    "    def get_max(self):\n",
    "        return [np.max(window) for window in self.data], [label + '_max' for label in self.indexed_labels]\n",
    "\n",
    "    def get_min(self):\n",
    "        return [np.min(window) for window in self.data], [label + '_min' for label in self.indexed_labels]\n",
    "\n",
    "    def get_std(self):\n",
    "        return [np.std(window) for window in self.data], [label + '_std' for label in self.indexed_labels]\n",
    "\n",
    "    def get_ptp(self):\n",
    "        return [np.ptp(window) for window in self.data], [label + '_ptp' for label in self.indexed_labels]\n",
    "\n",
    "    def get_avg(self):\n",
    "        return [np.average(window) for window in self.data], [label + '_avg' for label in self.indexed_labels]\n",
    "\n",
    "    def get_median(self):\n",
    "        return [np.median(window) for window in self.data], [label + '_median' for label in self.indexed_labels]\n",
    "\n",
    "    def get_mean(self):\n",
    "        return [np.mean(window) for window in self.data], [label + '_mean' for label in self.indexed_labels]\n",
    "\n",
    "    def get_pos(self):\n",
    "        return [len(window[window >= 0]) for window in self.data], [label + '_pos' for label in self.indexed_labels]\n",
    "\n",
    "    def get_neg(self):\n",
    "        return [len(window[window < 0]) for window in self.data], [label + '_neg' for label in self.indexed_labels]\n",
    "\n",
    "    def get_iqr(self):\n",
    "        return [np.percentile(window, 75) - np.percentile(window, 25) for window in self.data], [label + '_iqr' for label in self.indexed_labels]\n",
    "\n",
    "    def get_over_avg(self):\n",
    "        return [len(window[window > np.average(window)]) for window in self.data], [label + '_over_avg' for label in self.indexed_labels]\n",
    "\n",
    "    def get_peaks(self):\n",
    "        return [len(find_peaks(window)[0]) for window in self.data], [label + '_peaks' for label in self.indexed_labels]\n",
    "\n",
    "    def get_skew(self):\n",
    "        return [skew(window) for window in self.data], [label + '_skew' for label in self.indexed_labels]\n",
    "\n",
    "    def get_kurtosis(self):\n",
    "        print(pd.Series(self.data).apply(lambda x: x.mean()))\n",
    "        return [kurtosis(window) for window in self.data], [label + '_kurtosis' for label in self.indexed_labels]\n",
    "\n",
    "    def get_energy(self):\n",
    "        return [np.sum(window ** 2) / self.W for window in self.data], [label + '_energy' for label in self.indexed_labels]\n",
    "\n",
    "    def get_acc(self):\n",
    "        return [np.average(np.sqrt(self.data[start + i] ** 2 +\n",
    "                self.data[start + i + self.count] ** 2 +\n",
    "                self.data[start + i + self.count * 2] ** 2))\n",
    "                for start in range(0, len(self.data) , 3 * self.count)\n",
    "                for i in range(self.count)], 'acc_'\n",
    "\n",
    "    def get_aria(self):\n",
    "        return [np.sum(np.abs(self.data[start + i]) +\n",
    "                np.abs(self.data[start + i + self.count]) +\n",
    "                np.abs(self.data[start + i + self.count * 2]))\n",
    "                for start in range(0, len(self.data) , 3 * self.count)\n",
    "                for i in range(self.count)], 'aria_'\n",
    "\n",
    "    def get_all(self, no_3D = False):\n",
    "        results_max, labels_max = self.get_max()\n",
    "        results_min, labels_min = self.get_min()\n",
    "        results_std, labels_std = self.get_std()\n",
    "        results_ptp, labels_ptp = self.get_ptp()\n",
    "        results_avg, labels_avg = self.get_avg()\n",
    "        results_median, labels_median = self.get_median()\n",
    "        results_mean, labels_mean = self.get_mean()\n",
    "        results_pos, labels_pos = self.get_pos()\n",
    "        results_neg, labels_neg = self.get_neg()\n",
    "        results_iqr, labels_iqr = self.get_iqr()\n",
    "        results_over_avg, labels_over_avg = self.get_over_avg()\n",
    "        results_peaks, labels_peaks = self.get_peaks()\n",
    "        results_skew, labels_skew = self.get_skew()\n",
    "        results_kurtosis, labels_kurtosis = self.get_kurtosis()\n",
    "        results_energy, labels_energy = self.get_energy()\n",
    "\n",
    "        results = [*results_max, *results_min, *results_std, *results_ptp, *results_avg, *results_median, *results_mean,\n",
    "                   *results_pos, *results_neg, *results_iqr, *results_over_avg, *results_peaks, *results_skew,\n",
    "                   *results_kurtosis, *results_energy]\n",
    "        final_labels = [*labels_max, *labels_min, *labels_std, *labels_ptp, *labels_avg, *labels_median, *labels_mean,\n",
    "                        *labels_pos, *labels_neg, *labels_iqr, *labels_over_avg, *labels_peaks, *labels_skew,\n",
    "                        *labels_kurtosis, *labels_energy]\n",
    "\n",
    "        if no_3D == False:\n",
    "            results_acc, label_acc = self.get_acc()\n",
    "            results_aria, label_aria = self.get_aria()\n",
    "\n",
    "            labels_acc = [label_acc + str(i) for i in range(len(results_acc))]\n",
    "            labels_aria = [label_aria + str(i) for i in range(len(results_aria))]\n",
    "\n",
    "            results = [*results, *results_acc, *results_aria]\n",
    "            final_labels = [*final_labels, *labels_acc, *labels_aria]\n",
    "\n",
    "        return {final_labels[i]:[results[i]] for i in range(len(results))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RacketSports Test\n",
    "time_series_x_acc = X_train_sports['dim_0'].to_numpy()[0].to_numpy()\n",
    "time_series_y_acc = X_train_sports['dim_1'].to_numpy()[0].to_numpy()\n",
    "time_series_z_acc = X_train_sports['dim_2'].to_numpy()[0].to_numpy()\n",
    "time_series_x_giro = X_train_sports['dim_3'].to_numpy()[0].to_numpy()\n",
    "time_series_y_giro = X_train_sports['dim_4'].to_numpy()[0].to_numpy()\n",
    "time_series_z_giro = X_train_sports['dim_5'].to_numpy()[0].to_numpy()\n",
    "\n",
    "time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "# fe = feature_extractor(time_series, ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5'])\n",
    "\n",
    "results = fe.get_all()\n",
    "\n",
    "features_sports_train = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_train_sports)):\n",
    "    time_series_x_acc = X_train_sports['dim_0'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_acc = X_train_sports['dim_1'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_acc = X_train_sports['dim_2'].to_numpy()[i].to_numpy()\n",
    "    time_series_x_giro = X_train_sports['dim_3'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_giro = X_train_sports['dim_4'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_giro = X_train_sports['dim_5'].to_numpy()[i].to_numpy()\n",
    "\n",
    "    time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "    time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "    fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "    # fe = feature_extractor(time_series, ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5'])\n",
    "\n",
    "    results = fe.get_all()\n",
    "\n",
    "    features_sports_train = pd.concat([features_sports_train, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_sports_train.to_csv('features_sports_train.csv')\n",
    "\n",
    "# RacketSports Train\n",
    "time_series_x_acc = X_test_sports['dim_0'].to_numpy()[0].to_numpy()\n",
    "time_series_y_acc = X_test_sports['dim_1'].to_numpy()[0].to_numpy()\n",
    "time_series_z_acc = X_test_sports['dim_2'].to_numpy()[0].to_numpy()\n",
    "time_series_x_giro = X_test_sports['dim_3'].to_numpy()[0].to_numpy()\n",
    "time_series_y_giro = X_test_sports['dim_4'].to_numpy()[0].to_numpy()\n",
    "time_series_z_giro = X_test_sports['dim_5'].to_numpy()[0].to_numpy()\n",
    "\n",
    "time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "# fe = feature_extractor(time_series, ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5'])\n",
    "fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "results = fe.get_all()\n",
    "\n",
    "features_sports_test = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_test_sports)):\n",
    "    time_series_x_acc = X_test_sports['dim_0'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_acc = X_test_sports['dim_1'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_acc = X_test_sports['dim_2'].to_numpy()[i].to_numpy()\n",
    "    time_series_x_giro = X_test_sports['dim_3'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_giro = X_test_sports['dim_4'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_giro = X_test_sports['dim_5'].to_numpy()[i].to_numpy()\n",
    "\n",
    "    time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "    time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "    # fe = feature_extractor(time_series, ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5'])\n",
    "    fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "    results = fe.get_all()\n",
    "\n",
    "    features_sports_test = pd.concat([features_sports_test, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_sports_test.to_csv('features_sports_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mitbih train\n",
    "\n",
    "time_series = X_train_mitbih.to_numpy()[0]\n",
    "fe = feature_extractor([time_series], ['series'], W = 100, sample_step=12)\n",
    "results = fe.get_all(no_3D=True)\n",
    "features_mitbih_train = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_train_mitbih)):\n",
    "    print(i)\n",
    "    time_series = X_train_mitbih.to_numpy()[i]\n",
    "\n",
    "    # time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "    fe = feature_extractor([time_series], ['series'], W = 100, sample_step=12)\n",
    "    # fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "    results = fe.get_all(no_3D=True)\n",
    "\n",
    "    features_mitbih_train = pd.concat([features_mitbih_train, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_mitbih_train.to_csv('features_mitbih_train.csv')\n",
    "\n",
    "# Mitbih test\n",
    "time_series = X_test_mitbih.to_numpy()[0]\n",
    "fe = feature_extractor([time_series], ['series'], W = 100, sample_step=12)\n",
    "results = fe.get_all(no_3D=True)\n",
    "features_mitbih_test = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_test_mitbih)):\n",
    "    time_series = X_test_mitbih.to_numpy()[i]\n",
    "\n",
    "    # time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "    fe = feature_extractor([time_series], ['series'], W = 100, sample_step=12)\n",
    "    # fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "    results = fe.get_all(no_3D=True)\n",
    "\n",
    "    features_mitbih_test = pd.concat([features_mitbih_test, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_mitbih_test.to_csv('features_mitbih_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptbdb train\n",
    "print(len(X_train_ptbdb))\n",
    "for i in range(len(X_train_ptbdb)):\n",
    "    print(i)\n",
    "    time_series = X_train_ptbdb.to_numpy()[i]\n",
    "\n",
    "    # time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "    fe = feature_extractor([time_series], ['series'], W = 100, sample_step=12)\n",
    "    # fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "    results = fe.get_all(no_3D=True)\n",
    "\n",
    "    if i == 0:\n",
    "        features_ptbdb_train = pd.DataFrame.from_dict(results)\n",
    "    else:\n",
    "        features_ptbdb_train = pd.concat([features_ptbdb_train, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_ptbdb_train.to_csv('features_ptbdb_train.csv')\n",
    "\n",
    "# Ptbdb test\n",
    "for i in range(len(X_test_ptbdb)):\n",
    "    time_series = X_test_ptbdb.to_numpy()[i]\n",
    "\n",
    "    # time_series_fft = np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro])\n",
    "\n",
    "    fe = feature_extractor([time_series], ['series'], W = 100, sample_step=12)\n",
    "    # fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "    results = fe.get_all(no_3D=True)\n",
    "\n",
    "    if i == 0:\n",
    "        features_ptbdb_test = pd.DataFrame.from_dict(results)\n",
    "    else:\n",
    "        features_ptbdb_test = pd.concat([features_mitbih_test, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_ptbdb_test.to_csv('features_ptbdb_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functins = ['self.get_max()', 'self.get_min()', 'self.get_std()', 'self.get_ptp()', 'self.get_avg()', 'self.get_median()', 'self.get_mean()', 'self.get_pos()', 'self.get_neg()', 'self.get_iqr()', 'self.get_over_avg()', 'self.get_peaks()', 'self.get_skew()', 'self.get_kurtosis()', 'self.get_energy()', 'self.get_acc()', 'self.get_aria()']\n",
    "names = ['_max', '_min', '_std', '_ptp', '_avg', '_median', '_mean', '_pos', '_neg', '_iqr', '_over_avg', '_peaks', '_skew', '_kurtosis', '_energy', '_acc', '_aria']\n",
    "\n",
    "for i in range(len(functins)):\n",
    "    # print('results' + names[i] + ', labels' + names[i] + ' = ' + functins[i])\n",
    "    # print('*results' + names[i] + ',', end=\" \")\n",
    "    print('*labels' + names[i] + ',', end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                          min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None,\n",
    "                           verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "\n",
    "le = LabelEncoder().fit(y_train_sports)\n",
    "y_sports_train_enc = le.transform(y_train_sports)\n",
    "\n",
    "le = LabelEncoder().fit(y_test_sports)\n",
    "y_sports_test_enc = le.transform(y_test_sports)\n",
    "\n",
    "rf.fit(features_sports_train, y_sports_train_enc)\n",
    "y_pred_sports = rf.predict(features_sports_test)\n",
    "y_pred_proba_sports = rf.predict_proba(features_sports_test)\n",
    "print(y_sports_test_enc)\n",
    "print(y_pred_sports)\n",
    "print(y_pred_proba_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False,\n",
    "          tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr',\n",
    "            break_ties=False, random_state=None)\n",
    "\n",
    "svm.fit(features_sports_train, y_sports_train_enc)\n",
    "y_pred_svm_sports = svm.predict(features_sports_test)\n",
    "print(y_sports_test_enc)\n",
    "print(y_pred_svm_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('ECG', ignore_errors=True)\n",
    "shutil.rmtree('RacketSports', ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
