{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sktime\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install sklearn\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc\n",
    "from sktime.datasets import load_from_arff_to_dataframe\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "\n",
    "# for feature extractor\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# for gridsearch and models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating datasets and spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzips datasets\n",
    "with zipfile.ZipFile(\"datasets.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sports, y_train_sports = load_from_arff_to_dataframe('RacketSports\\RacketSports_TRAIN.arff')\n",
    "X_test_sports, y_test_sports = load_from_arff_to_dataframe('RacketSports\\RacketSports_TEST.arff')\n",
    "\n",
    "data_mitbih_train = pd.read_csv('ECG\\mitbih_train.csv', header=None)\n",
    "data_mitbih_test = pd.read_csv('ECG\\mitbih_test.csv', header=None)\n",
    "\n",
    "X_train_mitbih = data_mitbih_train.iloc[:, 0:-1]\n",
    "y_train_mitbih = data_mitbih_train.iloc[:, -1]\n",
    "\n",
    "X_test_mitbih = data_mitbih_test.iloc[:, 0:-1]\n",
    "y_test_mitbih = data_mitbih_test.iloc[:, -1]\n",
    "\n",
    "data_ptbdb_abnormal = pd.read_csv('ECG\\ptbdb_abnormal.csv', header=None)\n",
    "data_ptbdb_normal = pd.read_csv('ECG\\ptbdb_normal.csv', header=None)\n",
    "\n",
    "data_ptbdb = pd.concat([data_ptbdb_abnormal, data_ptbdb_normal])\n",
    "\n",
    "X_ptbdb = data_ptbdb.iloc[:, 0:-1]\n",
    "y_ptbdb = data_ptbdb.iloc[:, -1]\n",
    "\n",
    "X_train_ptbdb, X_test_ptbdb, y_train_ptbdb, y_test_ptbdb = train_test_split(X_ptbdb, y_ptbdb, test_size=0.2, random_state=80085)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the plotting\n",
    "labels_sports = ['Badminton_Smash',\n",
    "                'Badminton_Clear',\n",
    "                'Squash_ForehandBoast',\n",
    "                'Squash_BackhandBoast']\n",
    "\n",
    "labels_mitbih = list(range(5))\n",
    "\n",
    "labels_ptbdb = [0, 1]\n",
    "\n",
    "datasets = [y_train_sports, y_test_sports, y_train_mitbih, y_test_mitbih, y_train_ptbdb, y_test_ptbdb]\n",
    "\n",
    "plot_labels = [labels_sports, labels_mitbih, labels_ptbdb]\n",
    "plot_titles = ['RacketSports', 'ECG Heartbeat Categorization Dataset - MIT-BIH', 'ECG Heartbeat Categorization Dataset - PTB Diagnostic']\n",
    "plot_subtitles = ['Train Set', 'Test Set']\n",
    "\n",
    "sns.set(rc={'figure.autolayout': True})\n",
    "\n",
    "bg_color = '#E5E6F0'\n",
    "color_line = '#0F101A'\n",
    "colors = ['#5465FF', '#788BFF', '#9BB1FF', '#BFD7FF', '#D1EAFF', '#E2FDFF']\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(colors))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.1**\n",
    "\n",
    "Grafice ale frecvenÈ›ei de apariÈ›ie a fiecÄƒrei etichete (clase) Ã®n setul de date de antrenare / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '3.1/1/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "for index in range(len(datasets)):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7), facecolor=bg_color)\n",
    "    fig.suptitle(plot_subtitles[index % 2] + ' - ' + plot_titles[index // 2], fontsize=20)\n",
    "\n",
    "    sns.countplot(ax=axes[0], x=datasets[index], order=np.unique(plot_labels[index // 2]), edgecolor=color_line)\n",
    "    axes[0].set_facecolor(bg_color)\n",
    "\n",
    "    for p in axes[0].patches:\n",
    "        axes[0].bar_label(container=axes[0].containers[0])\n",
    "\n",
    "    counts = [len(datasets[index][datasets[index] == label]) for label in plot_labels[index//2]]\n",
    "    axes[1].pie(counts, labels=plot_labels[index // 2], autopct='%1.1f%%')\n",
    "\n",
    "    plt.savefig(results_dir + plot_titles[index // 2] + '_' + plot_subtitles[index % 2] + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.2**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) CÃ¢te un exemplu de serie pentru fiecare tip de acÈ›iune din RacketSports - val de acc accelerometru si de giroscop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(80085)\n",
    "results_dir = '3.1/2/1/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "for label in labels_sports:\n",
    "    indexes = random.sample([i for i in range(y_train_sports.shape[0]) if y_train_sports[i] == label], 6)\n",
    "\n",
    "    # 3D acc\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Accelerometru - 3D', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_acc = X_train_sports.to_numpy()[indexes[i]][0].to_numpy()\n",
    "        y_acc = X_train_sports.to_numpy()[indexes[i]][1].to_numpy()\n",
    "        z_acc = X_train_sports.to_numpy()[indexes[i]][2].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, projection='3d', facecolor=bg_color)\n",
    "        ax.plot(x_acc, y_acc, z_acc, color=colors[0], zorder=-1)\n",
    "        ax.plot(x_acc, y_acc, z_acc, color=colors[4], marker='*', markeredgecolor=colors[0], markeredgewidth=1, markersize=10, linestyle=' ')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Accelerometru_3d' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    # axis acc\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Accelerometru - axe', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_acc = X_train_sports.to_numpy()[indexes[i]][0].to_numpy()\n",
    "        y_acc = X_train_sports.to_numpy()[indexes[i]][1].to_numpy()\n",
    "        z_acc = X_train_sports.to_numpy()[indexes[i]][2].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(x_acc, color=colors[0])\n",
    "        ax.plot(y_acc, color=colors[2])\n",
    "        ax.plot(z_acc, color=colors[3])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Accelerometru_axis' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Giroscop - 3D', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_giro = X_train_sports.to_numpy()[indexes[i]][3].to_numpy()\n",
    "        y_giro = X_train_sports.to_numpy()[indexes[i]][4].to_numpy()\n",
    "        z_giro = X_train_sports.to_numpy()[indexes[i]][5].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, projection='3d', facecolor=bg_color)\n",
    "        ax.plot(x_giro, y_giro, z_giro, color=colors[0], zorder=-1)\n",
    "        ax.plot(x_giro, y_giro, z_giro, color=colors[4], marker='*', markeredgecolor=colors[0], markeredgewidth=1, markersize=10, linestyle=' ')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Giroscop_3d' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('RacketSports ' + label + ' Exemplu - Giroscop - axe', fontsize=20)\n",
    "    for i in range(6):\n",
    "\n",
    "        x_giro = X_train_sports.to_numpy()[indexes[i]][0].to_numpy()\n",
    "        y_giro = X_train_sports.to_numpy()[indexes[i]][1].to_numpy()\n",
    "        z_acc = X_train_sports.to_numpy()[indexes[i]][2].to_numpy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(x_giro, color=colors[0])\n",
    "        ax.plot(y_giro, color=colors[2])\n",
    "        ax.plot(z_giro, color=colors[3])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'RacketSports_' + label + '_Giroscop_axis' + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) CÃ¢te un exemplu de serie pentru fiecare categorie de aritmie din seturile de date MIT-BIH / PTB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(80085)\n",
    "results_dir = '3.1/2/2/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 'ECG Heartbeat Categorization Dataset - MIT-BIH', 'ECG Heartbeat Categorization Dataset - PTB Diagnostic'\n",
    "time_sample = list(range(187))\n",
    "\n",
    "for label in labels_mitbih:\n",
    "    indexes = random.sample([i for i in range(y_train_mitbih.shape[0]) if y_train_mitbih[i] == label], 6)\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - MIT-BIH ' + str(label) , fontsize=20)\n",
    "    for i in range(6):\n",
    "        series = X_train_mitbih.to_numpy()[indexes[i]]\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(time_sample, series, color=colors[0], zorder=-1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_MIT_BIH_' + str(label) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "for label in labels_ptbdb:\n",
    "    indexes = random.sample([i for i in range(y_train_ptbdb.shape[0]) if y_train_ptbdb.to_numpy()[i] == label], 6)\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.33), facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - PTB Diagnostic ' + str(label) , fontsize=20)\n",
    "    for i in range(6):\n",
    "        series = X_train_ptbdb.to_numpy()[indexes[i]]\n",
    "\n",
    "        ax = fig.add_subplot(2, 3, i + 1, facecolor=bg_color)\n",
    "        ax.plot(time_sample, series, color=colors[0], zorder=-1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_PTB_Diagnostic_' + str(label) + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Grafic al mediei È™i deviaÈ›iei standard per unitate de timp, pentru fiecare clasÄƒ de aritmie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '3.1/2/3/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "X_mitbih = pd.concat([X_train_mitbih, X_test_mitbih]).to_numpy()\n",
    "y_mitbih = pd.concat([y_train_mitbih, y_test_mitbih]).to_numpy()\n",
    "\n",
    "\n",
    "for label in labels_mitbih:\n",
    "    indexes = [i for i in range(y_mitbih.shape[0]) if y_mitbih[i] == label]\n",
    "\n",
    "    std_mitbih = np.std(X_mitbih[indexes], axis=0)\n",
    "    mean_mitbih = np.mean(X_mitbih[indexes], axis=0)\n",
    "\n",
    "    fig = plt.figure(facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - MIT-BIH ' + str(label) , fontsize=20)\n",
    "    ax = fig.add_subplot(1, 1, 1, facecolor=bg_color)\n",
    "    ax.set_title('Standard Deviation and Mean')\n",
    "    ax.plot(time_sample, std_mitbih, color=colors[3], linewidth=2.5)\n",
    "    ax.plot(time_sample, mean_mitbih, color=colors[2], linewidth=2, zorder=-1)\n",
    "\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_MIT_BIH_mean_std_' + str(label) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for label in labels_ptbdb:\n",
    "    indexes = [i for i in range(y_ptbdb.shape[0]) if y_ptbdb.to_numpy()[i] == label]\n",
    "    std_ptbdb = np.std(X_ptbdb.to_numpy()[indexes], axis=0)\n",
    "    mean_ptbdb = np.mean(X_ptbdb.to_numpy()[indexes], axis=0)\n",
    "\n",
    "    fig = plt.figure(facecolor=bg_color)\n",
    "    fig.suptitle('ECG Heartbeat Categorization Dataset - PTB Diagnostic ' + str(label) , fontsize=20)\n",
    "    ax = fig.add_subplot(1, 1, 1, facecolor=bg_color)\n",
    "    ax.set_title('Standard Deviation and Mean')\n",
    "    ax.plot(time_sample, std_ptbdb, color=colors[3], linewidth=2.5)\n",
    "    ax.plot(time_sample, mean_ptbdb, color=colors[2], linewidth=2, zorder=-1)\n",
    "    plt.savefig(results_dir + 'ECG_Heartbeat_Categorization_Dataset_PTB_Diagnostic_mean_std_' + str(label) + '.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Grafic al distributiei de valori per axa per actiune pt RacketSports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why did i do it like this? why is my code so inefficient? why is it so bad?\n",
    "# because i do not care anymore\n",
    "# ive spent literal hours of my life on this amazing ðŸ¤¬ thing and i do not want to see it anymore\n",
    "# now it works and i dont care\n",
    "# let it rot for all i care\n",
    "\n",
    "# AND I HAD TO CHANGE MY VIBES AESTHETIC PRETTY COLOR PALETTE FOR THIS\n",
    "\n",
    "results_dir = '3.1/2/4/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "colors2 = ['#cafe48', '#70f8ba', '#d14081', '#2583d0', '#733ab1', '#ff8811']\n",
    "\n",
    "data_sports_all = pd.concat([X_train_sports, X_test_sports], ignore_index=True)\n",
    "columns_sports = data_sports_all.columns\n",
    "y_sports_all = np.append(y_train_sports, y_test_sports)\n",
    "\n",
    "parsed_data = {}\n",
    "labels = []\n",
    "values = []\n",
    "dimensions = []\n",
    "\n",
    "for i in range(len(data_sports_all)):\n",
    "    for col in ['dim_0', 'dim_1']:\n",
    "        time_series = data_sports_all[col][i]\n",
    "        for value in time_series:\n",
    "            values.append(value)\n",
    "            labels.append(y_sports_all[i])\n",
    "            dimensions.append(col)\n",
    "\n",
    "parsed_data['value'] = values\n",
    "parsed_data['dimension'] = dimensions\n",
    "parsed_data['label'] = labels\n",
    "\n",
    "parsed_data = pd.DataFrame(parsed_data)\n",
    "\n",
    "g = sns.FacetGrid(parsed_data, col='dimension', hue='label', aspect=1.5, palette=sns.color_palette(colors)).map(sns.histplot, 'value', kde=True).add_legend()\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.savefig(results_dir + 'value_distr_1' + str(label) + '.png')\n",
    "\n",
    "parsed_data = {}\n",
    "labels = []\n",
    "values = []\n",
    "dimensions = []\n",
    "\n",
    "for i in range(len(data_sports_all)):\n",
    "    for col in ['dim_2', 'dim_3']:\n",
    "        time_series = data_sports_all[col][i]\n",
    "        for value in time_series:\n",
    "            values.append(value)\n",
    "            labels.append(y_sports_all[i])\n",
    "            dimensions.append(col)\n",
    "\n",
    "parsed_data['value'] = values\n",
    "parsed_data['dimension'] = dimensions\n",
    "parsed_data['label'] = labels\n",
    "\n",
    "parsed_data = pd.DataFrame(parsed_data)\n",
    "\n",
    "g = sns.FacetGrid(parsed_data, col='dimension', hue='label', aspect=1.5, palette=sns.color_palette(colors)).map(sns.histplot, 'value', kde=True)\n",
    "g.add_legend()\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.savefig(results_dir + 'value_distr_2' + str(label) + '.png')\n",
    "\n",
    "parsed_data = {}\n",
    "labels = []\n",
    "values = []\n",
    "dimensions = []\n",
    "\n",
    "for i in range(len(data_sports_all)):\n",
    "    for col in ['dim_4', 'dim_5']:\n",
    "        time_series = data_sports_all[col][i]\n",
    "        for value in time_series:\n",
    "            values.append(value)\n",
    "            labels.append(y_sports_all[i])\n",
    "            dimensions.append(col)\n",
    "\n",
    "parsed_data['value'] = values\n",
    "parsed_data['dimension'] = dimensions\n",
    "parsed_data['label'] = labels\n",
    "\n",
    "parsed_data = pd.DataFrame(parsed_data)\n",
    "\n",
    "g = sns.FacetGrid(parsed_data, col='dimension', hue='label', aspect=1.5, palette=sns.color_palette(colors)).map(sns.histplot, 'value', kde=True)\n",
    "g.add_legend()\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.savefig(results_dir + 'value_distr_2' + str(label) + '.png')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasa pentru extragerea de feature-uri\n",
    "- are window size si sample size reglabile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_extractor:\n",
    "    def __init__(self, time_series, labels, W=20, sample_step=15):\n",
    "        self.time_series = time_series\n",
    "        self.labels = labels\n",
    "        self.W = W\n",
    "        self.data = []\n",
    "        self.indexed_labels = []\n",
    "\n",
    "        for i in range(len(time_series)):\n",
    "            count = 0\n",
    "            for step in range(0, len(self.time_series[i]), sample_step):\n",
    "                self.data.append(self.time_series[i][step : step + self.W])\n",
    "                self.indexed_labels.append(self.labels[i] + '_' + str(count))\n",
    "                count += 1\n",
    "        self.count = count\n",
    "\n",
    "    def get_max(self):\n",
    "        return [np.max(window) for window in self.data], [label + '_max' for label in self.indexed_labels]\n",
    "\n",
    "    def get_min(self):\n",
    "        return [np.min(window) for window in self.data], [label + '_min' for label in self.indexed_labels]\n",
    "\n",
    "    def get_std(self):\n",
    "        return [np.std(window) for window in self.data], [label + '_std' for label in self.indexed_labels]\n",
    "\n",
    "    def get_ptp(self):\n",
    "        return [np.ptp(window) for window in self.data], [label + '_ptp' for label in self.indexed_labels]\n",
    "\n",
    "    def get_avg(self):\n",
    "        return [np.average(window) for window in self.data], [label + '_avg' for label in self.indexed_labels]\n",
    "\n",
    "    def get_median(self):\n",
    "        return [np.median(window) for window in self.data], [label + '_median' for label in self.indexed_labels]\n",
    "\n",
    "    def get_mean(self):\n",
    "        return [np.mean(window) for window in self.data], [label + '_mean' for label in self.indexed_labels]\n",
    "\n",
    "    def get_pos(self):\n",
    "        return [len(window[window >= 0]) for window in self.data], [label + '_pos' for label in self.indexed_labels]\n",
    "\n",
    "    def get_neg(self):\n",
    "        return [len(window[window < 0]) for window in self.data], [label + '_neg' for label in self.indexed_labels]\n",
    "\n",
    "    def get_iqr(self):\n",
    "        return [np.percentile(window, 75) - np.percentile(window, 25) for window in self.data], [label + '_iqr' for label in self.indexed_labels]\n",
    "\n",
    "    def get_over_avg(self):\n",
    "        return [len(window[window > np.average(window)]) for window in self.data], [label + '_over_avg' for label in self.indexed_labels]\n",
    "\n",
    "    def get_peaks(self):\n",
    "        return [len(find_peaks(window)[0]) for window in self.data], [label + '_peaks' for label in self.indexed_labels]\n",
    "\n",
    "    def get_skew(self):\n",
    "        return [skew(window) for window in self.data], [label + '_skew' for label in self.indexed_labels]\n",
    "\n",
    "    def get_kurtosis(self):\n",
    "        return [kurtosis(window) for window in self.data], [label + '_kurtosis' for label in self.indexed_labels]\n",
    "\n",
    "    def get_energy(self):\n",
    "        return [np.sum(window ** 2) / self.W for window in self.data], [label + '_energy' for label in self.indexed_labels]\n",
    "\n",
    "    def get_acc(self):\n",
    "        return [np.average(np.sqrt(self.data[start + i] ** 2 +\n",
    "                self.data[start + i + self.count] ** 2 +\n",
    "                self.data[start + i + self.count * 2] ** 2))\n",
    "                for start in range(0, len(self.data) , 3 * self.count)\n",
    "                for i in range(self.count)], 'acc_'\n",
    "\n",
    "    def get_aria(self):\n",
    "        return [np.sum(np.abs(self.data[start + i]) +\n",
    "                np.abs(self.data[start + i + self.count]) +\n",
    "                np.abs(self.data[start + i + self.count * 2]))\n",
    "                for start in range(0, len(self.data) , 3 * self.count)\n",
    "                for i in range(self.count)], 'aria_'\n",
    "\n",
    "    def get_all(self, no_3D = False):\n",
    "        results_max, labels_max = self.get_max()\n",
    "        results_min, labels_min = self.get_min()\n",
    "        results_std, labels_std = self.get_std()\n",
    "        results_ptp, labels_ptp = self.get_ptp()\n",
    "        results_avg, labels_avg = self.get_avg()\n",
    "        results_median, labels_median = self.get_median()\n",
    "        results_mean, labels_mean = self.get_mean()\n",
    "        results_pos, labels_pos = self.get_pos()\n",
    "        results_neg, labels_neg = self.get_neg()\n",
    "        results_iqr, labels_iqr = self.get_iqr()\n",
    "        results_over_avg, labels_over_avg = self.get_over_avg()\n",
    "        results_peaks, labels_peaks = self.get_peaks()\n",
    "        results_skew, labels_skew = self.get_skew()\n",
    "        results_kurtosis, labels_kurtosis = self.get_kurtosis()\n",
    "        results_energy, labels_energy = self.get_energy()\n",
    "\n",
    "        results = [*results_max, *results_min, *results_std, *results_ptp, *results_avg, *results_median, *results_mean,\n",
    "                   *results_pos, *results_neg, *results_iqr, *results_over_avg, *results_peaks, *results_skew,\n",
    "                   *results_kurtosis, *results_energy]\n",
    "        final_labels = [*labels_max, *labels_min, *labels_std, *labels_ptp, *labels_avg, *labels_median, *labels_mean,\n",
    "                        *labels_pos, *labels_neg, *labels_iqr, *labels_over_avg, *labels_peaks, *labels_skew,\n",
    "                        *labels_kurtosis, *labels_energy]\n",
    "\n",
    "        if no_3D == False:\n",
    "            results_acc, label_acc = self.get_acc()\n",
    "            results_aria, label_aria = self.get_aria()\n",
    "\n",
    "            labels_acc = [label_acc + str(i) for i in range(len(results_acc))]\n",
    "            labels_aria = [label_aria + str(i) for i in range(len(results_aria))]\n",
    "\n",
    "            results = [*results, *results_acc, *results_aria]\n",
    "            final_labels = [*final_labels, *labels_acc, *labels_aria]\n",
    "\n",
    "        return {final_labels[i]:[results[i]] for i in range(len(results))}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extragerea de atribute pt fiecare dataset\n",
    "- creeaza cate un csv pt fiecare ca sa pot sa le citesc din el direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RacketSports Test\n",
    "time_series_x_acc = X_train_sports['dim_0'].to_numpy()[0].to_numpy()\n",
    "time_series_y_acc = X_train_sports['dim_1'].to_numpy()[0].to_numpy()\n",
    "time_series_z_acc = X_train_sports['dim_2'].to_numpy()[0].to_numpy()\n",
    "time_series_x_giro = X_train_sports['dim_3'].to_numpy()[0].to_numpy()\n",
    "time_series_y_giro = X_train_sports['dim_4'].to_numpy()[0].to_numpy()\n",
    "time_series_z_giro = X_train_sports['dim_5'].to_numpy()[0].to_numpy()\n",
    "\n",
    "\n",
    "time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "time_series_fft = np.abs(np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]))\n",
    "\n",
    "fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "results = fe.get_all()\n",
    "\n",
    "features_sports_train = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_train_sports)):\n",
    "    time_series_x_acc = X_train_sports['dim_0'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_acc = X_train_sports['dim_1'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_acc = X_train_sports['dim_2'].to_numpy()[i].to_numpy()\n",
    "    time_series_x_giro = X_train_sports['dim_3'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_giro = X_train_sports['dim_4'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_giro = X_train_sports['dim_5'].to_numpy()[i].to_numpy()\n",
    "\n",
    "    time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "    time_series_fft = np.abs(np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]))\n",
    "\n",
    "    fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "    results = fe.get_all()\n",
    "\n",
    "    features_sports_train = pd.concat([features_sports_train, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_sports_train.to_csv('features_sports_train.csv')\n",
    "\n",
    "# RacketSports Train\n",
    "time_series_x_acc = X_test_sports['dim_0'].to_numpy()[0].to_numpy()\n",
    "time_series_y_acc = X_test_sports['dim_1'].to_numpy()[0].to_numpy()\n",
    "time_series_z_acc = X_test_sports['dim_2'].to_numpy()[0].to_numpy()\n",
    "time_series_x_giro = X_test_sports['dim_3'].to_numpy()[0].to_numpy()\n",
    "time_series_y_giro = X_test_sports['dim_4'].to_numpy()[0].to_numpy()\n",
    "time_series_z_giro = X_test_sports['dim_5'].to_numpy()[0].to_numpy()\n",
    "\n",
    "time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "time_series_fft = np.abs(np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]))\n",
    "\n",
    "fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "results = fe.get_all()\n",
    "\n",
    "features_sports_test = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_test_sports)):\n",
    "    time_series_x_acc = X_test_sports['dim_0'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_acc = X_test_sports['dim_1'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_acc = X_test_sports['dim_2'].to_numpy()[i].to_numpy()\n",
    "    time_series_x_giro = X_test_sports['dim_3'].to_numpy()[i].to_numpy()\n",
    "    time_series_y_giro = X_test_sports['dim_4'].to_numpy()[i].to_numpy()\n",
    "    time_series_z_giro = X_test_sports['dim_5'].to_numpy()[i].to_numpy()\n",
    "\n",
    "    time_series = [time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]\n",
    "    time_series_fft = np.abs(np.fft.fft([time_series_x_acc,  time_series_y_acc, time_series_z_acc, time_series_x_giro,  time_series_y_giro, time_series_z_giro]))\n",
    "\n",
    "    fe = feature_extractor([*time_series, *time_series_fft], ['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_0_fft', 'dim_1_fft', 'dim_2_fft', 'dim_3_fft', 'dim_4_fft', 'dim_5_fft'])\n",
    "\n",
    "    results = fe.get_all()\n",
    "\n",
    "    features_sports_test = pd.concat([features_sports_test, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_sports_test.to_csv('features_sports_test.csv')\n",
    "\n",
    "# Mitbih train\n",
    "\n",
    "time_series = X_train_mitbih.to_numpy()[0]\n",
    "fe = feature_extractor([time_series, np.abs(np.fft.fft(time_series))], ['series', 'series_fft'], W = 200, sample_step=200)\n",
    "results = fe.get_all(no_3D=True)\n",
    "features_mitbih_train = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_train_mitbih)):\n",
    "    time_series = X_train_mitbih.to_numpy()[i]\n",
    "\n",
    "    fe = feature_extractor([time_series, np.abs(np.fft.fft(time_series))], ['series', 'series_fft'], W = 200, sample_step=200)\n",
    "    results = fe.get_all(no_3D=True)\n",
    "    features_mitbih_train = pd.concat([features_mitbih_train, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_mitbih_train.to_csv('features_mitbih_train.csv')\n",
    "\n",
    "# Mitbih test\n",
    "time_series = X_test_mitbih.to_numpy()[0]\n",
    "fe = feature_extractor([time_series, np.abs(np.fft.fft(time_series))], ['series', 'series_fft'], W = 200, sample_step=200)\n",
    "results = fe.get_all(no_3D=True)\n",
    "features_mitbih_test = pd.DataFrame.from_dict(results)\n",
    "\n",
    "for i in range(1, len(X_test_mitbih)):\n",
    "    time_series = X_test_mitbih.to_numpy()[i]\n",
    "\n",
    "    fe = feature_extractor([time_series, np.abs(np.fft.fft(time_series))], ['series', 'series_fft'], W = 200, sample_step=200)\n",
    "    results = fe.get_all(no_3D=True)\n",
    "    features_mitbih_test = pd.concat([features_mitbih_test, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_mitbih_test.to_csv('features_mitbih_test.csv')\n",
    "\n",
    "# ptbdb train\n",
    "for i in range(len(X_train_ptbdb)):\n",
    "    time_series = X_train_ptbdb.to_numpy()[i].ravel()\n",
    "    time_series_fft = np.abs(np.fft.fft(time_series))\n",
    "\n",
    "    fe = feature_extractor([time_series, time_series_fft], ['series', 'series_fft'], W=200, sample_step=200)\n",
    "\n",
    "    results = fe.get_all(no_3D=True)\n",
    "\n",
    "    if i == 0:\n",
    "        features_ptbdb_train = pd.DataFrame.from_dict(results)\n",
    "    else:\n",
    "        features_ptbdb_train = pd.concat([features_ptbdb_train, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_ptbdb_train.to_csv('features_ptbdb_train.csv')\n",
    "\n",
    "# Ptbdb test\n",
    "for i in range(len(X_test_ptbdb)):\n",
    "    time_series = X_test_ptbdb.to_numpy()[i]\n",
    "    time_series_fft = np.abs(np.fft.fft(time_series))\n",
    "\n",
    "    fe = feature_extractor([time_series, time_series_fft], ['series', 'series_fft'], W=200, sample_step=200)\n",
    "\n",
    "    results = fe.get_all(no_3D=True)\n",
    "\n",
    "    if i == 0:\n",
    "        features_ptbdb_test = pd.DataFrame.from_dict(results)\n",
    "    else:\n",
    "        features_ptbdb_test = pd.concat([features_ptbdb_test, pd.DataFrame.from_dict(results)], ignore_index=True)\n",
    "\n",
    "features_ptbdb_test.to_csv('features_ptbdb_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder pt Sports\n",
    "var = VarianceThreshold(threshold=0.2)\n",
    "var.fit(features_sports_train)\n",
    "X_train_sports_selected = var.transform(features_sports_train)\n",
    "X_test_sports_selected = var.transform(features_sports_test)\n",
    "\n",
    "le = LabelEncoder().fit(y_train_sports)\n",
    "y_sports_train_enc = le.transform(y_train_sports)\n",
    "\n",
    "le = LabelEncoder().fit(y_test_sports)\n",
    "y_sports_test_enc = le.transform(y_test_sports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt printat scor/clasa\n",
    "# efectiv pain but ayaye :)\n",
    "def scorer_f1_by_class(y_true, y_predicted, class_):\n",
    "  result = f1_score(y_true, y_predicted, average=None, zero_division=0)\n",
    "  return result[class_]\n",
    "\n",
    "def scorer_precision_by_class(y_true, y_predicted, class_):\n",
    "  result = precision_score(y_true, y_predicted, average=None, zero_division=0)\n",
    "  return result[class_]\n",
    "\n",
    "def scorer_recall_by_class(y_true, y_predicted, class_):\n",
    "  result = recall_score(y_true, y_predicted, average=None, zero_division=0)\n",
    "  return result[class_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "scoring = {'f1_score': make_scorer(f1_score, average='macro'),\n",
    "           'accuracy': make_scorer(accuracy_score),\n",
    "           'f1_class_0': make_scorer(scorer_f1_by_class, class_=0),\n",
    "           'f1_class_1': make_scorer(scorer_f1_by_class, class_=1),\n",
    "           'f1_class_2': make_scorer(scorer_f1_by_class, class_=2),\n",
    "           'f1_class_3': make_scorer(scorer_f1_by_class, class_=3),\n",
    "           'precision_class_0': make_scorer(scorer_precision_by_class, class_=0),\n",
    "           'precision_class_1': make_scorer(scorer_precision_by_class, class_=1),\n",
    "           'precision_class_2': make_scorer(scorer_precision_by_class, class_=2),\n",
    "           'precision_class_3': make_scorer(scorer_precision_by_class, class_=3),\n",
    "           'recall_class_0': make_scorer(scorer_recall_by_class, class_=0),\n",
    "           'recall_class_1': make_scorer(scorer_recall_by_class, class_=1),\n",
    "           'recall_class_2': make_scorer(scorer_recall_by_class, class_=2),\n",
    "           'recall_class_3': make_scorer(scorer_recall_by_class, class_=3)}\n",
    "\n",
    "\n",
    "params = {'max_features' : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35],\n",
    "          'n_estimators' : [200, 235, 250, 270, 300],\n",
    "          'max_depth' : [30, 35, 40, 45],\n",
    "          'criterion' : ['gini'],\n",
    "          'n_jobs' : [-1],\n",
    "          'oob_score' : [True],\n",
    "          'warm_start' : [True, False]\n",
    "          }\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, scoring=scoring, refit='f1_score', verbose=3, return_train_score=True)\n",
    "grid.fit(X_train_sports_selected, y_sports_train_enc)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_index_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'criterion': 'gini',\n",
    "#  'max_depth': 35,\n",
    "#  'max_features': 0.1,\n",
    "#  'n_estimators': 200,\n",
    "#  'n_jobs': -1,\n",
    "#  'oob_score': True,\n",
    "#  'warm_start': True}\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=35, max_features=0.1, oob_score=True, n_jobs=-1, warm_start=True)\n",
    "\n",
    "rf.fit(X_train_sports_selected, y_sports_train_enc)\n",
    "\n",
    "y_pred_sports_rf = rf.predict(X_test_sports_selected)\n",
    "y_pred_proba_sports_rf = rf.predict_proba(X_test_sports_selected)\n",
    "cm_rf = confusion_matrix(y_sports_test_enc, y_pred_sports_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted = XGBClassifier()\n",
    "\n",
    "scoring = {'f1_score': make_scorer(f1_score, average='macro'),\n",
    "           'accuracy': make_scorer(accuracy_score),\n",
    "           'f1_class_0': make_scorer(scorer_f1_by_class, class_=0),\n",
    "           'f1_class_1': make_scorer(scorer_f1_by_class, class_=1),\n",
    "           'f1_class_2': make_scorer(scorer_f1_by_class, class_=2),\n",
    "           'f1_class_3': make_scorer(scorer_f1_by_class, class_=3),\n",
    "           'precision_class_0': make_scorer(scorer_precision_by_class, class_=0),\n",
    "           'precision_class_1': make_scorer(scorer_precision_by_class, class_=1),\n",
    "           'precision_class_2': make_scorer(scorer_precision_by_class, class_=2),\n",
    "           'precision_class_3': make_scorer(scorer_precision_by_class, class_=3),\n",
    "           'recall_class_0': make_scorer(scorer_recall_by_class, class_=0),\n",
    "           'recall_class_1': make_scorer(scorer_recall_by_class, class_=1),\n",
    "           'recall_class_2': make_scorer(scorer_recall_by_class, class_=2),\n",
    "           'recall_class_3': make_scorer(scorer_recall_by_class, class_=3)}\n",
    "\n",
    "# numÄƒrul de arbori, adÃ¢ncimea maximÄƒ a unui arbore,\n",
    "# learning rate\n",
    "\n",
    "params = {'max_features' : [0.05, 0.1, 0.15],\n",
    "          'n_estimators' : [50, 100, 200],\n",
    "          'max_depth' : [None, 30, 35, 40],\n",
    "          'n_jobs': [-1],\n",
    "\t      'verbosity' : [0],\n",
    "\t      'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "          'gamma': [0.3, 0.4, 0.5],\n",
    "\t      'learning_rate': [0.05, 0.1, 0.15]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=boosted, param_grid=params, cv=5, scoring=scoring, refit='f1_score', verbose=3, return_train_score=True)\n",
    "grid.fit(X_train_sports_selected, y_sports_train_enc)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_index_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'booster': 'gblinear', 'gamma': 0.3, 'learning_rate': 0.05, 'max_depth': 30, \n",
    "# 'max_features': 0.15, 'n_estimators': 50, 'n_jobs': -1, 'verbosity': 0}\n",
    "\n",
    "boosted = XGBClassifier(booster='gblinear', gamma=0.3, learning_rate=0.05, max_depth=30,\n",
    "                        max_features=0.15, n_estimators=50, n_jobs=-1, verbosity=0)\n",
    "boosted.fit(features_sports_train, y_sports_train_enc, eval_set=[(features_sports_test, y_sports_test_enc)], verbose=0)\n",
    "y_pred_sports_boosted = boosted.predict(features_sports_test)\n",
    "y_pred_proba_sports_boosted = rf.predict_proba(X_test_sports_selected)\n",
    "cm_boosted = confusion_matrix(y_sports_test_enc, y_pred_sports_boosted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipul de kernel, parametru C de regularizare\n",
    "svc = SVC()\n",
    "\n",
    "scoring = {'f1_score': make_scorer(f1_score, average='macro'),\n",
    "           'accuracy': make_scorer(accuracy_score),\n",
    "           'f1_class_0': make_scorer(scorer_f1_by_class, class_=0),\n",
    "           'f1_class_1': make_scorer(scorer_f1_by_class, class_=1),\n",
    "           'f1_class_2': make_scorer(scorer_f1_by_class, class_=2),\n",
    "           'f1_class_3': make_scorer(scorer_f1_by_class, class_=3),\n",
    "           'precision_class_0': make_scorer(scorer_precision_by_class, class_=0),\n",
    "           'precision_class_1': make_scorer(scorer_precision_by_class, class_=1),\n",
    "           'precision_class_2': make_scorer(scorer_precision_by_class, class_=2),\n",
    "           'precision_class_3': make_scorer(scorer_precision_by_class, class_=3),\n",
    "           'recall_class_0': make_scorer(scorer_recall_by_class, class_=0),\n",
    "           'recall_class_1': make_scorer(scorer_recall_by_class, class_=1),\n",
    "           'recall_class_2': make_scorer(scorer_recall_by_class, class_=2),\n",
    "           'recall_class_3': make_scorer(scorer_recall_by_class, class_=3)}\n",
    "\n",
    "params = {'C' : [0.1, 0.2, 0.3, 0.5, 1],\n",
    "          'kernel' : ['linear','poly', 'rbf', 'sigmoid'],\n",
    "          'degree' : [2, 3, 4],\n",
    "          'gamma': ['scale', 'auto'],\n",
    "          'shrinking': [True, False],\n",
    "          'decision_function_shape': ['ovo', 'ovr']}\n",
    "\n",
    "grid = GridSearchCV(estimator=svc, param_grid=params, cv=5, scoring=scoring, refit='f1_score', verbose=3, return_train_score=True)\n",
    "grid.fit(X_train_sports_selected, y_sports_train_enc)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_index_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 0.1, 'decision_function_shape': 'ovo', 'degree': 2, 'gamma': 'scale', 'kernel': 'linear', 'shrinking': True}\n",
    "\n",
    "svc = SVC(C=0.1, kernel='linear', degree=2, gamma='scale', shrinking=True, decision_function_shape='ovo')\n",
    "\n",
    "svc.fit(X_train_sports_selected, y_sports_train_enc)\n",
    "y_pred_sports_svc = rf.predict(X_test_sports_selected)\n",
    "y_pred_proba_sports_svc = rf.predict_proba(X_test_sports_selected)\n",
    "cm_svc = confusion_matrix(y_sports_test_enc, y_pred_sports_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '3.2/'\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "cms = [cm_rf, cm_boosted, cm_svc]\n",
    "name = ['RandomForest', 'Gradient Boosted Tree', 'SVC']\n",
    "\n",
    "for i in range(len(cms)):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cms[i])\n",
    "    disp.plot(include_values=True, cmap='cool', ax=None, xticks_rotation=\"vertical\")\n",
    "    plt.title(name[i] + ' Confusion Matrix')\n",
    "    plt.savefig(name[i] + '_cm.png')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(cms)):\n",
    "    for class_pos in range(len(labels_sports)):\n",
    "        y_test_all_vs_one = np.array([1 if y == class_pos else 0 for y in y_sports_test_enc])\n",
    "        roc_auc = roc_auc_score(y_test_all_vs_one, y_pred_proba_sports_svc[:, class_pos])\n",
    "        fpr, tpr, thresholds = roc_curve(y_test_all_vs_one, y_pred_proba_sports_svc[:, class_pos])\n",
    "        roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "        plt.text(0.95, 0.01, 'AUC = ' + str(roc_auc), verticalalignment='bottom', horizontalalignment='right')\n",
    "        plt.title(name[i] + 'ROC-AUC curve ' + labels_sports[class_pos])\n",
    "        plt.savefig(results_dir + name[i] + '_ROC_AUC_' + labels_sports[class_pos])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('ECG', ignore_errors=True)\n",
    "shutil.rmtree('RacketSports', ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
